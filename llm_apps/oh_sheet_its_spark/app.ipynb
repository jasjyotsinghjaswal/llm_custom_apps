{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "project_path = os.getenv(\"PROJECT_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"{project_path}\\llm_custom_apps\\llm_apps\\oh_sheet_its_spark\\utils.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': \"\\nYou are a helpful assistant to a Data Scientist who is working on a project to transform Excel Spreadsheets to PySpark Dataframes. \\nThe Data Scientist has provided you with a dictionary of dictionaries which contains details about Excel spreadsheets.\\nEach dictionary has only one key which is the name of the Sheet and the value is a dictionary with multiple keys.\\nEach key is the name of the Column Header in the Excel Spreadsheet. The value is again a dictionary with two keys.\\nThe first key is 'ColumnID' with the value being the associated ColumnID in Excel i.e. A, B, C, or etc.\\nThe second key is 'ColumnValue' with the value being the associated formula for generating the column or the hardcoded value in the absence of the formula.\\nThe dictionary looks something like:\\n\\n{{'SheetNum1': {'X': {'ColumnID': 'A', 'ColumnValue': 11},\\n   'Y': {'ColumnID': 'B', 'ColumnValue': 2020},\\n   'Z': {'ColumnID': 'C', 'ColumnValue': 15789},\\n   'P': {'ColumnID': 'D', 'ColumnValue': 'KIO'},\\n   'Q': {'ColumnID': 'E', 'ColumnValue': 'SECCC'}}},\\n {'SheetNum2': {'ID': {'ColumnID': 'A', 'LLOP': 1},\\n   'Location': {'ColumnID': 'B', 'ColumnValue': 'LOPP'}}}}\\n\\nYou have to convert the spreadsheet transformation logic to pyspark dataframe keeping the following in mind\\n\\n1) Parsing the dictionary figure out the dependency between sheets and between columns to identify the order in which the transformations need to be defined and the columns that are hardcoded.\\n2) In your response at the beginning provide explanation about the Sheets that are present.For each Sheet specify what columns are hardcoded and what columns are derived .Do not specify the values of the columns but only the column names.\\n3) Now respond with code with the code block starting with ```python and ending with ``` . Ensure:\\n  a) All the python dependencies that will be required to accomplish this task are imported and after declaring dependencies, also create a placeholder to read the spreadsheet creating multiple pyspark dataframes , one for each sheet in the spreadsheet if and only if it has atleast one hardcoded column (i.e. not derived using formula) and only read/select the hardcoded columns from dataframe.Rememeber I want you to create Dataframes from the individual sheets of spreadsheet and not creating them explictly from the hardcoded values in the dictionary provided\\n  b) Now create new dataframes from the dataframes declared as input and derive transformed columns for each of the column that is derived using formulas based on dictionary provided , with column name in pyspark being same as Column Header provided in the dictionary.\\n  c) Against each transformation (withColumn,agg methods, join etc. )  have in comments the Psuedo Code(Logic in plain english used to derive the column.) on the same line .\\n  d) Subsequently the user might ask for modications for removing /adding /modifying existing transformations to which you should comply accordingly by updating entire code with bare minimum explanation of the changes made.\\n\\n\\n\\n\"}, {'role': 'user', 'content': 'Convert the excel logic representation to equivalent pyspark code : {\\'SalesInfo\\': {\\'StoreID\\': {\\'ColumnID\\': \\'A\\', \\'ColumnValue\\': \\'11\\'}, \\'SalesYear\\': {\\'ColumnID\\': \\'B\\', \\'ColumnValue\\': \\'2020\\'}, \\'SalesValue\\': {\\'ColumnID\\': \\'C\\', \\'ColumnValue\\': \\'15789\\'}, \\'StoreLocation\\': {\\'ColumnID\\': \\'D\\', \\'ColumnValue\\': \\'=IFERROR(INDEX(RegionInfo!B:B, MATCH(INDEX(StoreInfo!B:B, MATCH(A2, StoreInfo!A:A, 0)), RegionInfo!A:A, 0)), \"\")\\'}, \\'Owner\\': {\\'ColumnID\\': \\'E\\', \\'ColumnValue\\': \\'=IFERROR(INDEX(StoreInfo!C:C, MATCH(A2, StoreInfo!A:A, 0)), \"\")\\'}}, \\'RegionInfo\\': {\\'ID\\': {\\'ColumnID\\': \\'A\\', \\'ColumnValue\\': \\'1\\'}, \\'Location\\': {\\'ColumnID\\': \\'B\\', \\'ColumnValue\\': \\'Halifax\\'}}, \\'StoreInfo\\': {\\'ID\\': {\\'ColumnID\\': \\'A\\', \\'ColumnValue\\': \\'11\\'}, \\'RegionID\\': {\\'ColumnID\\': \\'B\\', \\'ColumnValue\\': \\'1\\'}, \\'StoreOwner\\': {\\'ColumnID\\': \\'C\\', \\'ColumnValue\\': \\'Ethan Carter\\'}}, \\'SaleGrowthReport1\\': {\\'StoreID\\': {\\'ColumnID\\': \\'A\\', \\'ColumnValue\\': \\'=_xlfn.UNIQUE(_xlfn._xlws.FILTER(SalesInfo!A:A, SalesInfo!A:A<>\"\"))\\'}, \\'AverageSales\\': {\\'ColumnID\\': \\'B\\', \\'ColumnValue\\': \\'=AVERAGEIF(SalesInfo!A:A, A2, SalesInfo!C:C)\\'}, \\'MinSales\\': {\\'ColumnID\\': \\'C\\', \\'ColumnValue\\': \\'=MIN(IF(SalesInfo!A:A=A2, SalesInfo!C:C))\\'}, \\'MaxSales\\': {\\'ColumnID\\': \\'D\\', \\'ColumnValue\\': \\'=MAX(IF(SalesInfo!A:A=A2, SalesInfo!C:C))\\'}}, \\'SaleGrowthReport2\\': {\\'StoreLocation-SalesYear\\': {\\'ColumnID\\': \\'A\\', \\'ColumnValue\\': \\'=_xlfn.UNIQUE(SalesInfo!D:D & \"-\" & SalesInfo!B:B)\\'}, \\'Year\\': {\\'ColumnID\\': \\'B\\', \\'ColumnValue\\': \\'=RIGHT(A2, LEN(A2) - FIND(\"-\", A2))\\'}, \\'Location\\': {\\'ColumnID\\': \\'C\\', \\'ColumnValue\\': \\'=LEFT(A2, FIND(\"-\", A2) - 1)\\'}, \\'AverageSales\\': {\\'ColumnID\\': \\'D\\', \\'ColumnValue\\': \\'=AVERAGEIFS(SalesInfo!C:C, SalesInfo!B:B, B2, SalesInfo!D:D, C2)\\'}, \\'MinSales\\': {\\'ColumnID\\': \\'E\\', \\'ColumnValue\\': \\'=_xlfn.MINIFS(SalesInfo!C:C, SalesInfo!B:B, B2, SalesInfo!D:D, C2)\\'}, \\'MaxSales\\': {\\'ColumnID\\': \\'F\\', \\'ColumnValue\\': \\'=_xlfn.MAXIFS(SalesInfo!C:C, SalesInfo!B:B, B2, SalesInfo!D:D, C2)\\'}}}'}, {'role': 'assistant', 'content': '### Explanation of the Sheets and Columns\\n\\n- **SalesInfo:**\\n  - **Hardcoded Columns:** StoreID, SalesYear, SalesValue\\n  - **Derived Columns:** StoreLocation, Owner\\n\\n- **RegionInfo:**\\n  - **Hardcoded Columns:** All columns (ID, Location)\\n  - **Derived Columns:** None\\n\\n- **StoreInfo:**\\n  - **Hardcoded Columns:** All columns (ID, RegionID, StoreOwner)\\n  - **Derived Columns:** None\\n\\n- **SaleGrowthReport1:**\\n  - **Hardcoded Columns:** None\\n  - **Derived Columns:** StoreID, AverageSales, MinSales, MaxSales\\n\\n- **SaleGrowthReport2:**\\n  - **Hardcoded Columns:** None\\n  - **Derived Columns:** StoreLocation-SalesYear, Year, Location, AverageSales, MinSales, MaxSales\\n\\n### PySpark Code\\n\\n```python\\nfrom pyspark.sql import SparkSession\\nfrom pyspark.sql.functions import col, unique, avg, min, max, when, isnull, first, regexp_extract\\n\\n# Initialize Spark session\\nspark = SparkSession.builder \\\\\\n    .appName(\"Excel to PySpark DataFrame Transformation\") \\\\\\n    .getOrCreate()\\n\\n# Read the Excel sheets into DataFrames (Assuming only sheets with hardcoded values are read)\\nsales_info_df = spark.read \\\\\\n    .format(\"com.crealytics.spark.excel\") \\\\\\n    .option(\"header\", \"false\") \\\\\\n    .option(\"inferSchema\", \"true\") \\\\\\n    .option(\"dataAddress\", \"SalesInfo!A:D\") \\\\\\n    .load() \\\\\\n    .select(\\n        col(\"_c0\").alias(\"StoreID\"), \\n        col(\"_c1\").alias(\"SalesYear\"), \\n        col(\"_c2\").alias(\"SalesValue\")\\n    )\\n\\nregion_info_df = spark.read \\\\\\n    .format(\"com.crealytics.spark.excel\") \\\\\\n    .option(\"header\", \"false\") \\\\\\n    .option(\"inferSchema\", \"true\") \\\\\\n    .option(\"dataAddress\", \"RegionInfo!A:B\") \\\\\\n    .load() \\\\\\n    .select(\\n        col(\"_c0\").alias(\"ID\"), \\n        col(\"_c1\").alias(\"Location\")\\n    )\\n\\nstore_info_df = spark.read \\\\\\n    .format(\"com.crealytics.spark.excel\") \\\\\\n    .option(\"header\", \"false\") \\\\\\n    .option(\"inferSchema\", \"true\") \\\\\\n    .option(\"dataAddress\", \"StoreInfo!A:C\") \\\\\\n    .load() \\\\\\n    .select(\\n        col(\"_c0\").alias(\"ID\"), \\n        col(\"_c1\").alias(\"RegionID\"), \\n        col(\"_c2\").alias(\"StoreOwner\")\\n    )\\n\\n# Transforming SalesInfo to derive StoreLocation and Owner\\nsales_info_df = sales_info_df \\\\\\n    .join(store_info_df, sales_info_df.StoreID == store_info_df.ID, \"left\") \\\\\\n    .withColumn(\"Owner\", when(isnull(col(\"StoreOwner\")), \"\").otherwise(col(\"StoreOwner\"))) \\\\\\n    .drop(\"ID\", \"StoreOwner\") \\\\\\n    .join(region_info_df, store_info_df.RegionID == region_info_df.ID, \"left\") \\\\\\n    .withColumn(\"StoreLocation\", when(isnull(col(\"Location\")), \"\").otherwise(col(\"Location\"))) \\\\\\n    .drop(\"Location\", \"RegionID\")\\n\\n# Transforming SaleGrowthReport1 to derive StoreID, AverageSales, MinSales, MaxSales\\nsale_growth_report1_df = sales_info_df \\\\\\n    .groupBy(\"StoreID\") \\\\\\n    .agg(\\n        avg(\"SalesValue\").alias(\"AverageSales\"),\\n        min(\"SalesValue\").alias(\"MinSales\"),\\n        max(\"SalesValue\").alias(\"MaxSales\")\\n    )\\n\\n# Transforming SaleGrowthReport2 to derive StoreLocation-SalesYear, Year, Location, AverageSales, MinSales, MaxSales\\nsale_growth_report2_df = sales_info_df \\\\\\n    .withColumn(\"StoreLocation-SalesYear\", concat(col(\"StoreLocation\"), lit(\"-\"), col(\"SalesYear\"))) \\\\\\n    .select(\"StoreLocation-SalesYear\", \"StoreLocation\", \"SalesYear\", \"SalesValue\") \\\\\\n    .groupBy(\"StoreLocation-SalesYear\", \"StoreLocation\", \"SalesYear\") \\\\\\n    .agg(\\n        first(\"SalesYear\").alias(\"Year\"),\\n        first(\"StoreLocation\").alias(\"Location\"),\\n        avg(\"SalesValue\").alias(\"AverageSales\"),\\n        min(\"SalesValue\").alias(\"MinSales\"),\\n        max(\"SalesValue\").alias(\"MaxSales\")\\n    ) \\\\\\n    .select(\"StoreLocation-SalesYear\", \"Year\", \"Location\", \"AverageSales\", \"MinSales\", \"MaxSales\")\\n```\\n\\n### Explanation of the Code:\\n1. **Reading DataFrames:**\\n   - Only `SalesInfo`, `RegionInfo`, and `StoreInfo` are read from the Excel file as they have hardcoded columns.\\n   - The `SaleGrowthReport1` and `SaleGrowthReport2` are not read directly because they are derived.\\n\\n2. **Transformations:**\\n   - `SalesInfo`: Joins `RegionInfo` and `StoreInfo` to derive `StoreLocation` and `Owner`.\\n   - `SaleGrowthReport1`: Groups by `StoreID` to calculate `AverageSales`, `MinSales`, and `MaxSales`.\\n   - `SaleGrowthReport2`: Creates a new column `StoreLocation-SalesYear`, then groups by this column to calculate `Year`, `Location`, `AverageSales`, `MinSales`, and `MaxSales`.\\n\\n### Modifications:\\nFor any modifications such as adding/removing/modifying transformations, please specify the changes and I will update the code accordingly.'}, {'role': 'User', 'content': 'hi'}, {'role': 'assistant', 'content': 'Bot: ih'}]\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Initialize an empty list to maintain chat history & Message history\n",
    "chat_history = []\n",
    "msg_history = []\n",
    "inf_mdl_nm = \"Qwen/Qwen2.5-Coder-32B-Instruct\"\n",
    "file_uploaded = False  # Flag to track if a file is uploaded\n",
    "\n",
    "# Function to handle file upload\n",
    "def handle_file_upload(file):\n",
    "    global file_uploaded, chat_history, msg_history\n",
    "    if file:\n",
    "        # Reset histories on new file upload\n",
    "        chat_history = []\n",
    "        msg_history = []\n",
    "\n",
    "        file_uploaded = True  # Set the flag to True when a file is uploaded\n",
    "\n",
    "        # Extract the file name\n",
    "        file_name = file.name\n",
    "\n",
    "        initial_msg = gen_initial_msg(file_name)\n",
    "        cd_resp = generate_responses_from_inf(hf_token,initial_msg,inf_mdl_nm,5000)\n",
    "\n",
    "        # Add the \"File Loaded\" message to msg_history only\n",
    "        msg_history.append(initial_msg[0])\n",
    "        msg_history.append(initial_msg[1])\n",
    "        \n",
    "        # Add the bot's response with the file name to both chat_history and msg_history\n",
    "        bot_message = f\"The file name is: {file_name}\"\n",
    "        chat_history.append((\"Bot\", cd_resp))\n",
    "        msg_history.append({'role': \"assistant\", 'content': cd_resp})\n",
    "\n",
    "        # Generate the formatted chat history\n",
    "        conversation_history = format_chat_history(chat_history)\n",
    "\n",
    "        return \"File uploaded successfully. You can now start chatting!\", conversation_history\n",
    "    else:\n",
    "        file_uploaded = False\n",
    "        return \"Please upload a valid Excel file.\", \"\"\n",
    "\n",
    "# Function to format chat history for display\n",
    "def format_chat_history(chat_history):\n",
    "    conversation_history = '''\n",
    "        <div style=\"border: 2px solid #ddd; padding: 20px; max-height: 300px; overflow-y: auto; background: #f0f0f0; display: flex; flex-direction: column; border-radius: 10px; box-shadow: 0 4px 10px rgba(0,0,0,0.1);\">\n",
    "    '''\n",
    "    for speaker, message in chat_history:\n",
    "        if speaker == \"User\":\n",
    "            conversation_history += f'''\n",
    "                <div style=\"display: flex; justify-content: flex-start; margin-bottom: 10px;\">\n",
    "                    <div style=\"background-color: #d0f7d6; color: #3b8e3a; padding: 10px; border-radius: 12px; max-width: 60%; word-wrap: break-word;\">\n",
    "                        <b>{speaker}:</b> {message}\n",
    "                    </div>\n",
    "                </div>\n",
    "            '''\n",
    "        else:\n",
    "            conversation_history += f'''\n",
    "                <div style=\"display: flex; justify-content: flex-end; margin-bottom: 10px;\">\n",
    "                    <div style=\"background-color: #ffffff; padding: 10px; border-radius: 12px; max-width: 60%; word-wrap: break-word;\">\n",
    "                        <b>{speaker}:</b> {message}\n",
    "                    </div>\n",
    "                </div>\n",
    "            '''\n",
    "    conversation_history += \"</div>\"\n",
    "    return conversation_history\n",
    "\n",
    "# Function to enable chat input and submit button after file upload\n",
    "def enable_chat_components(file_status):\n",
    "    if \"successfully\" in file_status.lower():\n",
    "        return gr.update(interactive=True), gr.update(interactive=True)\n",
    "    else:\n",
    "        return gr.update(interactive=False), gr.update(interactive=False)\n",
    "\n",
    "# Function to handle chat history\n",
    "def chatbot_history(user_input):\n",
    "    global chat_history  # Use the global chat_history list\n",
    "    global msg_history\n",
    "\n",
    "    # Append user input to the chat history\n",
    "    chat_history.append((\"User\", user_input))\n",
    "    msg_history.append({'role': \"User\", 'content': user_input})\n",
    "\n",
    "    # Generate a response (you can replace this with more complex logic)\n",
    "    bot_response = f\"Bot: {user_input[::-1]}\"  # Reverse input for fun\n",
    "    msg_history.append({'role': \"assistant\", 'content': bot_response})\n",
    "\n",
    "    # Append bot response to chat history\n",
    "    chat_history.append((\"Bot\", bot_response))\n",
    "\n",
    "    # Create a formatted string of the conversation history\n",
    "    conversation_history = format_chat_history(chat_history)\n",
    "\n",
    "    print(msg_history)\n",
    "\n",
    "    # Return the formatted conversation history and clear the input field\n",
    "    return conversation_history, \"\"\n",
    "\n",
    "# Create Gradio interface using Blocks with Soft theme\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    # Add a title with proper font\n",
    "    gr.HTML(\"\"\"\n",
    "        <div style=\"font-size: 2.5em; color: #4CAF50; font-weight: bold; text-align: center;\">\n",
    "            Oh Sheet!!!!! It's Spark\n",
    "        </div>\n",
    "    \"\"\")\n",
    "\n",
    "    # Layout with chat and input section\n",
    "    with gr.Row():\n",
    "        # Message section on the left (30% width)\n",
    "        with gr.Column(scale=1, min_width=30):\n",
    "            # File uploader at the top\n",
    "            file_upload = gr.File(label=\"Upload an Excel File\", file_types=[\".xls\", \".xlsx\"], interactive=True)\n",
    "            file_status = gr.Textbox(label=\"\", interactive=False, lines=1, value=\"Please upload an Excel file to begin.\", show_label=False)\n",
    "\n",
    "            # Chatbox and submit button\n",
    "            input_text = gr.Textbox(label=\"Enter your message\", lines=1, interactive=False)  # Initially disabled\n",
    "            submit_button = gr.Button(\"Submit\", variant=\"primary\", interactive=False)  # Initially disabled\n",
    "\n",
    "        # Chatbot section on the right (70% width)\n",
    "        with gr.Column(scale=2, min_width=70):\n",
    "            output_text = gr.HTML(label=\"Chatbot History\", elem_id=\"chat_history\")\n",
    "\n",
    "    # Ensure file upload enables the chatbox\n",
    "    file_upload.change(fn=handle_file_upload, inputs=file_upload, outputs=[file_status, output_text])\n",
    "    file_status.change(fn=enable_chat_components, inputs=file_status, outputs=[input_text, submit_button])\n",
    "\n",
    "    # Ensure Enter key is mapped to submit functionality\n",
    "    input_text.submit(fn=chatbot_history, inputs=input_text, outputs=[output_text, input_text])\n",
    "    submit_button.click(fn=chatbot_history, inputs=input_text, outputs=[output_text, input_text])\n",
    "\n",
    "# Launch the app\n",
    "demo.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
