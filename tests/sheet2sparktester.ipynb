{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "project_path = os.getenv(\"PROJECT_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"{project_path}\\llm_custom_apps\\llm_apps\\oh_sheet_its_spark\\utils.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SalesInfo': {'StoreID': {'ColumnID': 'A'},\n",
       "  'SalesYear': {'ColumnID': 'B'},\n",
       "  'SalesValue': {'ColumnID': 'C'},\n",
       "  'StoreLocation': {'ColumnID': 'D'},\n",
       "  'Owner': {'ColumnID': 'E'}},\n",
       " 'RegionInfo': {'ID': {'ColumnID': 'A'}, 'Location': {'ColumnID': 'B'}},\n",
       " 'StoreInfo': {'ID': {'ColumnID': 'A'},\n",
       "  'RegionID': {'ColumnID': 'B'},\n",
       "  'StoreOwner': {'ColumnID': 'C'}},\n",
       " 'SaleGrowthReport1': {'StoreID': {'ColumnID': 'A'},\n",
       "  'AverageSales': {'ColumnID': 'B'},\n",
       "  'MinSales': {'ColumnID': 'C'},\n",
       "  'MaxSales': {'ColumnID': 'D'}},\n",
       " 'SaleGrowthReport2': {'StoreLocation-SalesYear': {'ColumnID': 'A'},\n",
       "  'Year': {'ColumnID': 'B'},\n",
       "  'Location': {'ColumnID': 'C'},\n",
       "  'AverageSales': {'ColumnID': 'D'},\n",
       "  'MinSales': {'ColumnID': 'E'},\n",
       "  'MaxSales': {'ColumnID': 'F'}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xls_col_info = get_excel_col_header(f\"{test_data_path}\\SalesData1.xlsx\")\n",
    "xls_col_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SalesInfo': {'StoreID': {'ColumnID': 'A', 'ColumnValue': '11'},\n",
       "  'SalesYear': {'ColumnID': 'B', 'ColumnValue': '2020'},\n",
       "  'SalesValue': {'ColumnID': 'C', 'ColumnValue': '15789'},\n",
       "  'StoreLocation': {'ColumnID': 'D',\n",
       "   'ColumnValue': '=IFERROR(INDEX(RegionInfo!B:B, MATCH(INDEX(StoreInfo!B:B, MATCH(A2, StoreInfo!A:A, 0)), RegionInfo!A:A, 0)), \"\")'},\n",
       "  'Owner': {'ColumnID': 'E',\n",
       "   'ColumnValue': '=IFERROR(INDEX(StoreInfo!C:C, MATCH(A2, StoreInfo!A:A, 0)), \"\")'}},\n",
       " 'RegionInfo': {'ID': {'ColumnID': 'A', 'ColumnValue': '1'},\n",
       "  'Location': {'ColumnID': 'B', 'ColumnValue': 'Halifax'}},\n",
       " 'StoreInfo': {'ID': {'ColumnID': 'A', 'ColumnValue': '11'},\n",
       "  'RegionID': {'ColumnID': 'B', 'ColumnValue': '1'},\n",
       "  'StoreOwner': {'ColumnID': 'C', 'ColumnValue': 'Ethan Carter'}},\n",
       " 'SaleGrowthReport1': {'StoreID': {'ColumnID': 'A',\n",
       "   'ColumnValue': '=_xlfn.UNIQUE(_xlfn._xlws.FILTER(SalesInfo!A:A, SalesInfo!A:A<>\"\"))'},\n",
       "  'AverageSales': {'ColumnID': 'B',\n",
       "   'ColumnValue': '=AVERAGEIF(SalesInfo!A:A, A2, SalesInfo!C:C)'},\n",
       "  'MinSales': {'ColumnID': 'C',\n",
       "   'ColumnValue': '=MIN(IF(SalesInfo!A:A=A2, SalesInfo!C:C))'},\n",
       "  'MaxSales': {'ColumnID': 'D',\n",
       "   'ColumnValue': '=MAX(IF(SalesInfo!A:A=A2, SalesInfo!C:C))'}},\n",
       " 'SaleGrowthReport2': {'StoreLocation-SalesYear': {'ColumnID': 'A',\n",
       "   'ColumnValue': '=_xlfn.UNIQUE(SalesInfo!D:D & \"-\" & SalesInfo!B:B)'},\n",
       "  'Year': {'ColumnID': 'B',\n",
       "   'ColumnValue': '=RIGHT(A2, LEN(A2) - FIND(\"-\", A2))'},\n",
       "  'Location': {'ColumnID': 'C', 'ColumnValue': '=LEFT(A2, FIND(\"-\", A2) - 1)'},\n",
       "  'AverageSales': {'ColumnID': 'D',\n",
       "   'ColumnValue': '=AVERAGEIFS(SalesInfo!C:C, SalesInfo!B:B, B2, SalesInfo!D:D, C2)'},\n",
       "  'MinSales': {'ColumnID': 'E',\n",
       "   'ColumnValue': '=_xlfn.MINIFS(SalesInfo!C:C, SalesInfo!B:B, B2, SalesInfo!D:D, C2)'},\n",
       "  'MaxSales': {'ColumnID': 'F',\n",
       "   'ColumnValue': '=_xlfn.MAXIFS(SalesInfo!C:C, SalesInfo!B:B, B2, SalesInfo!D:D, C2)'}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xls_str = process_excel_columns_xlwings(f\"{test_data_path}\\SalesData1.xlsx\",xls_col_info)\n",
    "xls_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": sheet_spark_prompt},\n",
    "    {\"role\": \"user\", \"content\": f\"Convert the excel logic representation to equivalent pyspark code : {xls_str}\"},\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Message being Sent : [{'role': 'system', 'content': \"\\nYou are a helpful assistant to a Data Scientist who is working on a project to transform Excel Spreadsheets to PySpark Dataframes. \\nThe Data Scientist has provided you with a dictionary of dictionaries which contains details about Excel spreadsheets.\\nEach dictionary has only one key which is the name of the Sheet and the value is a dictionary with multiple keys.\\nEach key is the name of the Column Header in the Excel Spreadsheet. The value is again a dictionary with two keys.\\nThe first key is 'ColumnID' with the value being the associated ColumnID in Excel i.e. A, B, C, or etc.\\nThe second key is 'ColumnValue' with the value being the associated formula for generating the column or the hardcoded value in the absence of the formula.\\nThe dictionary looks something like:\\n\\n{{'SheetNum1': {'X': {'ColumnID': 'A', 'ColumnValue': 11},\\n   'Y': {'ColumnID': 'B', 'ColumnValue': 2020},\\n   'Z': {'ColumnID': 'C', 'ColumnValue': 15789},\\n   'P': {'ColumnID': 'D', 'ColumnValue': 'KIO'},\\n   'Q': {'ColumnID': 'E', 'ColumnValue': 'SECCC'}}},\\n {'SheetNum2': {'ID': {'ColumnID': 'A', 'LLOP': 1},\\n   'Location': {'ColumnID': 'B', 'ColumnValue': 'LOPP'}}}}\\n\\nYou have to convert the spreadsheet transformation logic to pyspark dataframe keeping the following in mind\\n\\n1) Parsing the dictionary figure out the dependency between sheets and between columns to identify the order in which the transformations need to be defined and the columns that are hardcoded.\\n2) In your response at the beginning provide explanation about the Sheets that are present.For each Sheet specify what columns are hardcoded and what columns are derived .Do not specify the values of the columns but only the column names.\\n3) Now respond with code with the code block starting with ```python and ending with ``` . Ensure:\\n  a) All the python dependencies that will be required to accomplish this task are imported and after declaring dependencies, also create a placeholder to read the spreadsheet creating multiple pyspark dataframes , one for each sheet in the spreadsheet if and only if it has atleast one hardcoded column (i.e. not derived using formula) and only read/select the hardcoded columns from dataframe.Rememeber I want you to create Dataframes from the individual sheets of spreadsheet and not creating them explictly from the hardcoded values in the dictionary provided\\n  b) Now create new dataframes from the dataframes declared as input and derive transformed columns for each of the column that is derived using formulas based on dictionary provided , with column name in pyspark being same as Column Header provided in the dictionary.\\n  c) Against each transformation (withColumn,agg methods, join etc. )  have in comments the Psuedo Code(Logic in plain english used to derive the column.) on the same line .\\n  d) Subsequently the user might ask for modications for removing /adding /modifying existing transformations to which you should comply accordingly by updating entire code with bare minimum explanation of the changes made.\\n\\n\\n\\n\"}, {'role': 'user', 'content': 'Convert the excel logic representation to equivalent pyspark code : {\\'SalesInfo\\': {\\'StoreID\\': {\\'ColumnID\\': \\'A\\', \\'ColumnValue\\': \\'11\\'}, \\'SalesYear\\': {\\'ColumnID\\': \\'B\\', \\'ColumnValue\\': \\'2020\\'}, \\'SalesValue\\': {\\'ColumnID\\': \\'C\\', \\'ColumnValue\\': \\'15789\\'}, \\'StoreLocation\\': {\\'ColumnID\\': \\'D\\', \\'ColumnValue\\': \\'=IFERROR(INDEX(RegionInfo!B:B, MATCH(INDEX(StoreInfo!B:B, MATCH(A2, StoreInfo!A:A, 0)), RegionInfo!A:A, 0)), \"\")\\'}, \\'Owner\\': {\\'ColumnID\\': \\'E\\', \\'ColumnValue\\': \\'=IFERROR(INDEX(StoreInfo!C:C, MATCH(A2, StoreInfo!A:A, 0)), \"\")\\'}}, \\'RegionInfo\\': {\\'ID\\': {\\'ColumnID\\': \\'A\\', \\'ColumnValue\\': \\'1\\'}, \\'Location\\': {\\'ColumnID\\': \\'B\\', \\'ColumnValue\\': \\'Halifax\\'}}, \\'StoreInfo\\': {\\'ID\\': {\\'ColumnID\\': \\'A\\', \\'ColumnValue\\': \\'11\\'}, \\'RegionID\\': {\\'ColumnID\\': \\'B\\', \\'ColumnValue\\': \\'1\\'}, \\'StoreOwner\\': {\\'ColumnID\\': \\'C\\', \\'ColumnValue\\': \\'Ethan Carter\\'}}, \\'SaleGrowthReport1\\': {\\'StoreID\\': {\\'ColumnID\\': \\'A\\', \\'ColumnValue\\': \\'=_xlfn.UNIQUE(_xlfn._xlws.FILTER(SalesInfo!A:A, SalesInfo!A:A<>\"\"))\\'}, \\'AverageSales\\': {\\'ColumnID\\': \\'B\\', \\'ColumnValue\\': \\'=AVERAGEIF(SalesInfo!A:A, A2, SalesInfo!C:C)\\'}, \\'MinSales\\': {\\'ColumnID\\': \\'C\\', \\'ColumnValue\\': \\'=MIN(IF(SalesInfo!A:A=A2, SalesInfo!C:C))\\'}, \\'MaxSales\\': {\\'ColumnID\\': \\'D\\', \\'ColumnValue\\': \\'=MAX(IF(SalesInfo!A:A=A2, SalesInfo!C:C))\\'}}, \\'SaleGrowthReport2\\': {\\'StoreLocation-SalesYear\\': {\\'ColumnID\\': \\'A\\', \\'ColumnValue\\': \\'=_xlfn.UNIQUE(SalesInfo!D:D & \"-\" & SalesInfo!B:B)\\'}, \\'Year\\': {\\'ColumnID\\': \\'B\\', \\'ColumnValue\\': \\'=RIGHT(A2, LEN(A2) - FIND(\"-\", A2))\\'}, \\'Location\\': {\\'ColumnID\\': \\'C\\', \\'ColumnValue\\': \\'=LEFT(A2, FIND(\"-\", A2) - 1)\\'}, \\'AverageSales\\': {\\'ColumnID\\': \\'D\\', \\'ColumnValue\\': \\'=AVERAGEIFS(SalesInfo!C:C, SalesInfo!B:B, B2, SalesInfo!D:D, C2)\\'}, \\'MinSales\\': {\\'ColumnID\\': \\'E\\', \\'ColumnValue\\': \\'=_xlfn.MINIFS(SalesInfo!C:C, SalesInfo!B:B, B2, SalesInfo!D:D, C2)\\'}, \\'MaxSales\\': {\\'ColumnID\\': \\'F\\', \\'ColumnValue\\': \\'=_xlfn.MAXIFS(SalesInfo!C:C, SalesInfo!B:B, B2, SalesInfo!D:D, C2)\\'}}}'}] \n"
     ]
    }
   ],
   "source": [
    "cd_resp = generate_responses_from_inf(hf_token,messages,\"Qwen/Qwen2.5-Coder-32B-Instruct\",5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Explanation of Sheets\n",
       "\n",
       "1. **SalesInfo**\n",
       "   - **Hardcoded Columns:** StoreID, SalesYear, SalesValue\n",
       "   - **Derived Columns:** StoreLocation, Owner\n",
       "\n",
       "2. **RegionInfo**\n",
       "   - **Hardcoded Columns:** ID, Location\n",
       "   - **Derived Columns:** None\n",
       "\n",
       "3. **StoreInfo**\n",
       "   - **Hardcoded Columns:** ID, RegionID, StoreOwner\n",
       "   - **Derived Columns:** None\n",
       "\n",
       "4. **SaleGrowthReport1**\n",
       "   - **Hardcoded Columns:** None\n",
       "   - **Derived Columns:** StoreID, AverageSales, MinSales, MaxSales\n",
       "\n",
       "5. **SaleGrowthReport2**\n",
       "   - **Hardcoded Columns:** None\n",
       "   - **Derived Columns:** StoreLocation-SalesYear, Year, Location, AverageSales, MinSales, MaxSales\n",
       "\n",
       "### Pyspark Code\n",
       "\n",
       "```python\n",
       "from pyspark.sql import SparkSession\n",
       "from pyspark.sql.functions import col, when, first, avg, min, max, uniq, concat_ws, substring, locate, length, expr\n",
       "\n",
       "# Initialize Spark session\n",
       "spark = SparkSession.builder.appName(\"ExcelToPySpark\").getOrCreate()\n",
       "\n",
       "# Placeholder to read Excel sheets into DataFrames\n",
       "sales_info_df = spark.read.format(\"excel\").option(\"header\", \"true\").sheet(\"SalesInfo\").load()\n",
       "region_info_df = spark.read.format(\"excel\").option(\"header\", \"true\").sheet(\"RegionInfo\").load()\n",
       "store_info_df = spark.read.format(\"excel\").option(\"header\", \"true\").sheet(\"StoreInfo\").load()\n",
       "\n",
       "# Select only hardcoded columns from DataFrames\n",
       "sales_info_df = sales_info_df.select(\"StoreID\", \"SalesYear\", \"SalesValue\")\n",
       "\n",
       "# Derive new columns for SalesInfo\n",
       "sales_info_df = sales_info_df.join(store_info_df.withColumnRenamed(\"ID\", \"StoreID\"), \"StoreID\", \"left\") \\\n",
       "    .join(region_info_df.withColumnRenamed(\"ID\", \"RegionID\"), \"RegionID\", \"left\") \\\n",
       "    .withColumn(\"StoreLocation\", when(expr(\"RegionInfo.Location is not null\"), col(\"RegionInfo.Location\")).otherwise(\"\")) \\\n",
       "    .withColumn(\"Owner\", when(expr(\"StoreInfo.StoreOwner is not null\"), col(\"StoreInfo.StoreOwner\")).otherwise(\"\")) \\\n",
       "    .drop(\"RegionID\", \"RegionInfo.Location\", \"StoreInfo.StoreOwner\")\n",
       "\n",
       "# Derive new DataFrames for SaleGrowthReport1\n",
       "sale_growth_report1_df = sales_info_df.groupBy(\"StoreID\").agg(\n",
       "    avg(\"SalesValue\").alias(\"AverageSales\"),  # Pseudo Code: AVERAGEIF(SalesInfo!A:A, A2, SalesInfo!C:C)\n",
       "    min(\"SalesValue\").alias(\"MinSales\"),      # Pseudo Code: MIN(IF(SalesInfo!A:A=A2, SalesInfo!C:C))\n",
       "    max(\"SalesValue\").alias(\"MaxSales\")       # Pseudo Code: MAX(IF(SalesInfo!A:A=A2, SalesInfo!C:C))\n",
       ")\n",
       "\n",
       "# Derive new DataFrames for SaleGrowthReport2\n",
       "sale_growth_report2_df = sales_info_df.withColumn(\"StoreLocation-SalesYear\", concat_ws(\"-\", col(\"StoreLocation\"), col(\"SalesYear\"))) \\\n",
       "    .groupBy(\"StoreLocation-SalesYear\").agg(\n",
       "        first(substring(col(\"StoreLocation-SalesYear\"), 1, locate(\"-\", col(\"StoreLocation-SalesYear\")) - 1)).alias(\"Location\"),  # Pseudo Code: LEFT(A2, FIND(\"-\", A2) - 1)\n",
       "        first(substring(col(\"StoreLocation-SalesYear\"), locate(\"-\", col(\"StoreLocation-SalesYear\")) + 1, length(col(\"StoreLocation-SalesYear\")) - locate(\"-\", col(\"StoreLocation-SalesYear\")))).alias(\"Year\"),  # Pseudo Code: RIGHT(A2, LEN(A2) - FIND(\"-\", A2))\n",
       "        avg(\"SalesValue\").alias(\"AverageSales\"),  # Pseudo Code: AVERAGEIFS(SalesInfo!C:C, SalesInfo!B:B, B2, SalesInfo!D:D, C2)\n",
       "        min(\"SalesValue\").alias(\"MinSales\"),      # Pseudo Code: MINIFS(SalesInfo!C:C, SalesInfo!B:B, B2, SalesInfo!D:D, C2)\n",
       "        max(\"SalesValue\").alias(\"MaxSales\")       # Pseudo Code: MAXIFS(SalesInfo!C:C, SalesInfo!B:B, B2, SalesInfo!D:D, C2)\n",
       "    ) \\\n",
       "    .drop(\"StoreLocation-SalesYear\")\n",
       "\n",
       "# Display the DataFrames (for testing purposes)\n",
       "sales_info_df.show()\n",
       "sale_growth_report1_df.show()\n",
       "sale_growth_report2_df.show()\n",
       "```\n",
       "\n",
       "### Explanation of Changes:\n",
       "1. **Imported Required Functions:** Imported necessary functions from `pyspark.sql.functions`.\n",
       "2. **Read Excel Sheets:** Used `spark.read.format(\"excel\").option(\"header\", \"true\").sheet(...).load()` to read appropriate sheets and select only hardcoded columns where necessary.\n",
       "3. **Derived Columns:** Used `withColumn` and `join` to derive columns based on the given Excel formulas, with comments explaining the pseudo code logic.\n",
       "4. **Aggregation:** Used `groupBy` and `agg` to aggregate data for derived columns in `SaleGrowthReport1` and `SaleGrowthReport2`.\n",
       "\n",
       "If you need modifications, feel free to ask, and I'll update the code accordingly."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(cd_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
