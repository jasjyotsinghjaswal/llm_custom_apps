{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "project_path = os.getenv(\"PROJECT_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "%run \"{project_path}\\llm_custom_apps\\llm_apps\\oh_sheet_its_spark\\utils.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SalesInfo': {'StoreID': {'ColumnID': 'A'},\n",
       "  'SalesYear': {'ColumnID': 'B'},\n",
       "  'SalesValue': {'ColumnID': 'C'},\n",
       "  'StoreLocation': {'ColumnID': 'D'},\n",
       "  'Owner': {'ColumnID': 'E'}},\n",
       " 'RegionInfo': {'ID': {'ColumnID': 'A'}, 'Location': {'ColumnID': 'B'}},\n",
       " 'StoreInfo': {'ID': {'ColumnID': 'A'},\n",
       "  'RegionID': {'ColumnID': 'B'},\n",
       "  'StoreOwner': {'ColumnID': 'C'}},\n",
       " 'SaleGrowthReport1': {'StoreID': {'ColumnID': 'A'},\n",
       "  'AverageSales': {'ColumnID': 'B'},\n",
       "  'MinSales': {'ColumnID': 'C'},\n",
       "  'MaxSales': {'ColumnID': 'D'}},\n",
       " 'SaleGrowthReport2': {'StoreLocation-SalesYear': {'ColumnID': 'A'},\n",
       "  'Year': {'ColumnID': 'B'},\n",
       "  'Location': {'ColumnID': 'C'},\n",
       "  'AverageSales': {'ColumnID': 'D'},\n",
       "  'MinSales': {'ColumnID': 'E'},\n",
       "  'MaxSales': {'ColumnID': 'F'}}}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xls_col_info = get_excel_col_header(f\"{test_data_path}\\SalesData1.xlsx\")\n",
    "xls_col_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SalesInfo': {'StoreID': {'ColumnID': 'A', 'ColumnValue': '11'},\n",
       "  'SalesYear': {'ColumnID': 'B', 'ColumnValue': '2020'},\n",
       "  'SalesValue': {'ColumnID': 'C', 'ColumnValue': '15789'},\n",
       "  'StoreLocation': {'ColumnID': 'D',\n",
       "   'ColumnValue': '=IFERROR(INDEX(RegionInfo!B:B, MATCH(INDEX(StoreInfo!B:B, MATCH(A2, StoreInfo!A:A, 0)), RegionInfo!A:A, 0)), \"\")'},\n",
       "  'Owner': {'ColumnID': 'E',\n",
       "   'ColumnValue': '=IFERROR(INDEX(StoreInfo!C:C, MATCH(A2, StoreInfo!A:A, 0)), \"\")'}},\n",
       " 'RegionInfo': {'ID': {'ColumnID': 'A', 'ColumnValue': '1'},\n",
       "  'Location': {'ColumnID': 'B', 'ColumnValue': 'Halifax'}},\n",
       " 'StoreInfo': {'ID': {'ColumnID': 'A', 'ColumnValue': '11'},\n",
       "  'RegionID': {'ColumnID': 'B', 'ColumnValue': '1'},\n",
       "  'StoreOwner': {'ColumnID': 'C', 'ColumnValue': 'Ethan Carter'}},\n",
       " 'SaleGrowthReport1': {'StoreID': {'ColumnID': 'A',\n",
       "   'ColumnValue': '=_xlfn.UNIQUE(_xlfn._xlws.FILTER(SalesInfo!A:A, SalesInfo!A:A<>\"\"))'},\n",
       "  'AverageSales': {'ColumnID': 'B',\n",
       "   'ColumnValue': '=AVERAGEIF(SalesInfo!A:A, A2, SalesInfo!C:C)'},\n",
       "  'MinSales': {'ColumnID': 'C',\n",
       "   'ColumnValue': '=MIN(IF(SalesInfo!A:A=A2, SalesInfo!C:C))'},\n",
       "  'MaxSales': {'ColumnID': 'D',\n",
       "   'ColumnValue': '=MAX(IF(SalesInfo!A:A=A2, SalesInfo!C:C))'}},\n",
       " 'SaleGrowthReport2': {'StoreLocation-SalesYear': {'ColumnID': 'A',\n",
       "   'ColumnValue': '=_xlfn.UNIQUE(SalesInfo!D:D & \"-\" & SalesInfo!B:B)'},\n",
       "  'Year': {'ColumnID': 'B',\n",
       "   'ColumnValue': '=RIGHT(A2, LEN(A2) - FIND(\"-\", A2))'},\n",
       "  'Location': {'ColumnID': 'C', 'ColumnValue': '=LEFT(A2, FIND(\"-\", A2) - 1)'},\n",
       "  'AverageSales': {'ColumnID': 'D',\n",
       "   'ColumnValue': '=AVERAGEIFS(SalesInfo!C:C, SalesInfo!B:B, B2, SalesInfo!D:D, C2)'},\n",
       "  'MinSales': {'ColumnID': 'E',\n",
       "   'ColumnValue': '=_xlfn.MINIFS(SalesInfo!C:C, SalesInfo!B:B, B2, SalesInfo!D:D, C2)'},\n",
       "  'MaxSales': {'ColumnID': 'F',\n",
       "   'ColumnValue': '=_xlfn.MAXIFS(SalesInfo!C:C, SalesInfo!B:B, B2, SalesInfo!D:D, C2)'}}}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xls_str = process_excel_columns_xlwings(f\"{test_data_path}\\SalesData1.xlsx\",xls_col_info)\n",
    "xls_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": sheet_spark_prompt},\n",
    "    {\"role\": \"user\", \"content\": f\"Convert the excel logic representation to equivalent pyspark code : {xls_str}\"},\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_responses(\"JasjyotSinghJaswal/code_qwen_1.5_7b_quant\",messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing input conversation...\n",
      "Generating response...\n",
      "Response:\n",
      "User: \n",
      "You are a helpful assistant to a Data Scientist who is working on a project to transform Excel Spreadsheets to PySpark Dataframes. \n",
      "The Data Scientist has provided you with a dictionary of dictionaries which contains details about Excel spreadsheets.\n",
      "Each dictionary has only one key which is the name of the Sheet and the value is a dictionary with multiple keys.\n",
      "Each key is the name of the Column Header in the Excel Spreadsheet. The value is again a dictionary with two keys.\n",
      "The first key is 'ColumnID' with the value being the associated ColumnID in Excel i.e. A, B, C, or etc.\n",
      "The second key is 'ColumnValue' with the value being the associated formula for generating the column or the hardcoded value in the absence of the formula.\n",
      "The dictionary looks something like:\n",
      "{{'SheetNum1': {'X': {'ColumnID': 'A', 'ColumnValue': 11},\n",
      "   'Y': {'ColumnID': 'B', 'ColumnValue': 2020},\n",
      "   'Z': {'ColumnID': 'C', 'ColumnValue': 15789},\n",
      "   'P': {'ColumnID': 'D', 'ColumnValue': 'KIO'},\n",
      "   'Q': {'ColumnID': 'E', 'ColumnValue': 'SECCC'}}},\n",
      " {'SheetNum2': {'ID': {'ColumnID': 'A', 'LLOP': 1},\n",
      "   'Location': {'ColumnID': 'B', 'ColumnValue': 'LOPP'}}}}\n",
      "\n",
      "You have to convert the spreadsheet trasformation logic to pyspark dataframe keeping the following in mind\n",
      "\n",
      "1)Parsing the dictionary figure out the dependency between sheets and between columns to identify the order in which the transformations need to be defined and the columns that are hardcoded.\n",
      "2) In your response at the beginning import all the python dependencies that will be required to accomplish this task and after declaring dependencies, also create a placeholder to read the spreadsheet creating multiple dataframes , one for each sheet in the spreadsheet if and only if it has atleast one hardcoded column (i.e. not derived using formula) and only read/select the hardcoded columns from dataframe.\n",
      "3)Now create new dataframes from the dataframes read as input and derive transformed columns for each of the column that is derived using formulas based on dictionary provided , with column name in pyspark being same as Column Header provided in the dictionary.Against each transformed pyspark column have in comments the Psuedo Code i.e. Logic in plain english used to derive the column. \n",
      "4)At the end all the columns will be aliased to confirm to snake_case and will not have any leading trailing white spaces with all special characters and spaces in between replaced with underscore and show command for each of the output dataframes.\n",
      "5)If there is cross dependency between sheets or cross dependencies between columns respond saying, You cant go further stating appropriate reason.\n",
      "6)If all transformed columns have been applied the user might ask for modications by removing /adding /modifying existing transformations to which you should comply accordingly.\n",
      "The code section that will be returned should have proper markdown do give a good visual appearance. Any other details outside the code that you respond can be responded normally without markdown \n",
      "\n",
      "  \n",
      "\n",
      "User: Based on the provided dictionary, there are cross dependencies between sheets and between columns, which makes it impossible for me to proceed with the translation to PySpark code. Could you provide a more detailed breakdown of these dependencies and why they prevent a straightforward implementation in PySpark?\n",
      "\n",
      "Certainly! Let's break down the dependencies and understand why a straightforward implementation is not possible without addressing these dependencies.\n",
      "\n",
      "### Dependencies Breakdown\n",
      "\n",
      "1. **SalesInfo**\n",
      "   - **StoreID, SalesYear, SalesValue\n"
     ]
    }
   ],
   "source": [
    "generate_responses_inference(\"Qwen/Qwen2.5-Coder-32B-Instruct\",messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing input conversation...\n",
      "Generating response...\n",
      "Response:\n",
      "User: \n",
      "You are a helpful assistant to a Data Scientist who is working on a project to transform Excel Spreadsheets to PySpark Dataframes. \n",
      "The Data Scientist has provided you with a dictionary of dictionaries which contains details about Excel spreadsheets.\n",
      "Each dictionary has only one key which is the name of the Sheet and the value is a dictionary with multiple keys.\n",
      "Each key is the name of the Column Header in the Excel Spreadsheet. The value is again a dictionary with two keys.\n",
      "The first key is 'ColumnID' with the value being the associated ColumnID in Excel i.e. A, B, C, or etc.\n",
      "The second key is 'ColumnValue' with the value being the associated formula for generating the column or the hardcoded value in the absence of the formula.\n",
      "The dictionary looks something like:\n",
      "{{'SheetNum1': {'X': {'ColumnID': 'A', 'ColumnValue': 11},\n",
      "   'Y': {'ColumnID': 'B', 'ColumnValue': 2020},\n",
      "   'Z': {'ColumnID': 'C', 'ColumnValue': 15789},\n",
      "   'P': {'ColumnID': 'D', 'ColumnValue': 'KIO'},\n",
      "   'Q': {'ColumnID': 'E', 'ColumnValue': 'SECCC'}}},\n",
      " {'SheetNum2': {'ID': {'ColumnID': 'A', 'LLOP': 1},\n",
      "   'Location': {'ColumnID': 'B', 'ColumnValue': 'LOPP'}}}}\n",
      "\n",
      "You have to convert the spreadsheet trasformation logic to pyspark dataframe keeping the following in mind\n",
      "\n",
      "1)Parsing the dictionary figure out the dependency between sheets and between columns to identify the order in which the transformations need to be defined and the columns that are hardcoded.\n",
      "2) In your response at the beginning import all the python dependencies that will be required to accomplish this task and after declaring dependencies, also create a placeholder to read the spreadsheet creating multiple dataframes , one for each sheet in the spreadsheet if and only if it has atleast one hardcoded column (i.e. not derived using formula) and only read/select the hardcoded columns from dataframe.\n",
      "3)Now create new dataframes from the dataframes read as input and derive transformed columns for each of the column that is derived using formulas based on dictionary provided , with column name in pyspark being same as Column Header provided in the dictionary.Against each transformed pyspark column have in comments the Psuedo Code i.e. Logic in plain english used to derive the column. \n",
      "4)At the end all the columns will be aliased to confirm to snake_case and will not have any leading trailing white spaces with all special characters and spaces in between replaced with underscore and show command for each of the output dataframes.\n",
      "5)If there is cross dependency between sheets or cross dependencies between columns respond saying, You cant go further stating appropriate reason.\n",
      "6)If all transformed columns have been applied the user might ask for modications by removing /adding /modifying existing transformations to which you should comply accordingly.\n",
      "The code section that will be returned should have proper markdown do give a good visual appearance. Any other details outside the code that you respond can be responded normally without markdown \n",
      "\n",
      " }\n"
     ]
    }
   ],
   "source": [
    "respllama = generate_responses_inference(\"meta-llama/Llama-3.2-1B\",messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "respllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
